#
# Sample properties file for JXTandem Launcher
#
#
# may be specified on the command line as well
#params=tandem.xml
#
# If using a cluster this is the hdfs directory    if unspecified
# will run locally
# use line below to run remotely
 #use line below to run on the cluster
#remoteBaseDirectory=/user/howdah/JXTandem/data/<LOCAL_DIRECTORY>
#use line below to run on the ec2
#remoteBaseDirectory=s3n://lordjoe/<LOCAL_DIRECTORY>
#
#  hdfs job tracker
remoteHost=glados
#
#  port on the job tracker
remotePort= 9000
#
#  Actual job tracker with port - not the same as name node port
remoteJobTracker= glados:9001
#
#  user on the job tracker
remoteUser=slewis
#
#  encrypted password  on the job tracker alternative is plainTextRemotePassword
#encryptedRemotePassword=aWnQ4DbdoSGivLcfi56hGKK8tx+LnqEYory3H4ueoRiivLcfi56hGA==
#
#  plain password  on the job tracker alternative is encryptedRemotePassword
#plainTextRemotePassword=secret

#
#
# Maximum number of peptides to handle ina reducer - raising this will raise the memory requirements on the cluster
# default is 1000
maxPeptideFragmentsPerReducer=50000

#
# sets mapres.max.splt.size
#  a lower number forces more mappers in my splitters which is good
# the default is 64mb but for what we are doing smaller seems to be better
# when mappers do a lot of work - this is 16 megs
#maxSplitSize=16777216
#maxSplitSize=20000000

#
# MaxReduceTasks tunes the cluster - increase this number for
# bigger clusters
maxReduceTasks = 36

#
#
# delete hadoop directories after the process is finished with them
# set fo false if debugging and the intermediate data wants to be examined
deleteOutputDirectories=true
 #
 # compressed files take less space and are harder to read
# set false if you plan to manually read intermediate files
compressIntermediateFiles=true
 #
 # Maximum memory assigned to child tasks  in megabytes
 # maps to "mapred.child.java.opts", "-Xmx" + maxMamory + "m"
maxClusterMemory=3600

#
# override specific Hadoop prepoerties - save writing specific code
DEFINE_io.sort.factor=100
DEFINE_io.sort.mb=400
# don't start reducers until most mappers done
DEFINE_mapred.reduce.slowstart.completed.maps=0.5
#  number of map tasks for the database
DEFINE_org.systemsbiology.jxtandem.DesiredDatabaseMappers=8
#  number of map tasks for the spectra
DEFINE_org.systemsbiology.jxtandem.DesiredXMLInputMappers=7
# save a scans file
DEFINE_org.systemsbiology.xtandem.SaveScansData=yes
# Write out PepXML
DEFINE_org.systemsbiology.xtandem.hadoop.WritePepXML=yes
# use multiple algorithms
DEFINE_org.systemsbiology.algorithm=org.systemsbiology.xtandem.morpheus.MorpheusScoringAlgorithm
#DEFINE_org.systemsbiology.algorithm=org.systemsbiology.xtandem.TandemKScoringAlgorithm;org.systemsbiology.xtandem.probidx.ProbIdScoringAlgorithm

# try spot instances
DEFINE_org.systemsbiology.aws.UseSpotMaster=yes
# use 6 instances
DEFINE_org.systemsbiology.aws.ClusterSize=9
# keep the cluster running
DEFINE_org.systemsbiology.aws.KeepClusterAfterJob=yes
# use this jar
#DEFINE_org.systemsbiology.tandem.hadoop.PrebuiltJar=Mar300846_0.jar
DEFINE_org.systemsbiology.aws.InstanceSize=large
# use multiple output files
DEFINE_org.systemsbiology.xtandem.MultipleOutputFiles=yes
# use hard coded modificatons = currently only CYSTEIN_MODIFICATION_MASS = -57.02146;
#DEFINE_org.systemsbiology.xtandem.HardCodeModifications=yes
